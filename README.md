# annotated-transformer-Chinese
 Transformer论文Attention is All You Need的代码中文注释实现，翻译自harvardnlp/annotated-transformer❤

原始项目：harvardnlp/annotated-transformer
作者：Alexander Rush
MIT许可证

原版博客文章:
[nlp.seas.harvard.edu](http://nlp.seas.harvard.edu/annotated-transformer/)

复现论文：
[Attention is All You Need](https://arxiv.org/abs/1706.03762)

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/harvardnlp/annotated-transformer/blob/master/AnnotatedTransformer.ipynb)

![image](https://user-images.githubusercontent.com/35882/166251887-9da909a9-660b-45a9-ae72-0aae89fb38d4.png)
