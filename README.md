# annotated-transformer-Chinese
Transformer论文Attention is All You Need的代码中文注释实现，翻译自harvardnlp/annotated-transformer
本项目是对原始项目 The Annotated Transformer 的中文翻译和注解版本。旨在使原始项目更加直观、易于理解，并提供中文示例以帮助读者更好地使用该项目。

这里对原始项目进行了大量的中文翻译，同时对一些导致不可运行的问题进行了修复。此外，还添加了详细的注解，以帮助读者更好地理解相关概念和流程。

欢迎提交pr继续进行翻译、修缮和注解工作（比如也可以试试加上transformer实现中英翻译的示例？）

如果发现有不妥之处欢迎指正❤

原始项目：[harvardnlp/annotated-transformer](https://github.com/harvardnlp/annotated-transformer/)
Copyright (c) 2018 Alexander Rush
v2022: Austin Huang, Suraj Subramanian, Jonathan Sum, Khalid Almubarak, and Stella Biderman.
Original: Sasha Rush.
MIT License

原版博客文章:
[nlp.seas.harvard.edu](http://nlp.seas.harvard.edu/annotated-transformer/)

复现论文：
[Attention is All You Need](https://arxiv.org/abs/1706.03762)

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/harvardnlp/annotated-transformer/blob/master/AnnotatedTransformer.ipynb)

![image](https://user-images.githubusercontent.com/35882/166251887-9da909a9-660b-45a9-ae72-0aae89fb38d4.png)
